\documentclass{article}
\newcommand{\hwnumber}{2}

\newcommand{\norm}[1]{\| #1 \|}
\newcommand{\abs}[1]{| #1 |}

\usepackage{fullpage,amsthm,amsmath,amssymb}
\usepackage{algorithm,algorithmic}
\usepackage{mathtools}
\usepackage{bbm,bm}
\usepackage{enumerate}
\usepackage{xspace}
\usepackage[textsize=tiny,
%disable
]{todonotes}
\newcommand{\todot}[1]{\todo[color=blue!20!white]{T: #1}}
\newcommand{\todoc}[1]{\todo[color=orange!20!white]{Cs: #1}}
\usepackage[colorlinks,citecolor=blue,urlcolor=blue,linkcolor=black]{hyperref}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

\renewcommand{\epsilon}{\varepsilon}
\renewcommand{\phi}{\varphi}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\one}[1]{\mathbb{I}_{\{#1\}}}
\newcommand{\oneb}[1]{\mathbb{I}_{#1}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\cZ}{\mathcal{Z}}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator*{\Exp}{\mathbf{E}}
\DeclareMathOperator*{\1}{\mathbbm{1}}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\E}{\mathbb E}
\newcommand{\bbP}{\mathbb P}
\newcommand{\V}{\mathbb V}
\renewcommand{\P}[1]{\bbP\left( #1 \right)}
\newcommand{\Prob}[1]{\mathbb{P}( #1 )}
\newcommand{\real}{\mathbb{R}}
\renewcommand{\b}[1]{\mathbf{#1}}
\newcommand{\EE}[1]{\E[#1]}
\newcommand{\bfone}{\1}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\0}{\mathbf{0}}
\usepackage[capitalize]{cleveref}
\usepackage{xifthen}

% total number of points that can be collected
\newcounter{DocPoints} % counter reset to zero upon creation

% counting points per question (not user facing)
\newcounter{QuestionPoints} % counter reset to zero upon creation

% Points for a subquestion of a question; 
% Adds the points to the total for the question and the document.
\newcommand{\points}[1]{%
	\par\mbox{}\par\noindent\hfill {\bf #1 points}%
	\addtocounter{DocPoints}{#1}
	\addtocounter{QuestionPoints}{#1}
}
% Points for a question; call with no params if the question
% had subquestions. In this case it prints the total for the question (see \points).
% Otherwise call with the points that the question is worth.
% In this case, the total is added to the document total.
% It is a semantic error to call this with a non-empty parameter
% when a question had subquestions with individual scores.
\newcommand{\tpoints}[1]{        %
	\ifthenelse{\isempty{#1}}%
	{%
	}%
	{%
		\addtocounter{DocPoints}{#1}
		\addtocounter{QuestionPoints}{#1}
	}													 %
	\par\mbox{}\par\noindent\hfill {Total: \bf \arabic{QuestionPoints}\xspace points}\par\mbox{}\par\hrule\hrule
	\setcounter{QuestionPoints}{0}
}
\newcommand{\tpoint}[1]{
	\tpoints{#1}
}

\theoremstyle{definition}
\newtheorem{question}{Question}

\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem*{remark*}{Remark}
\newtheorem{solution}{Solution}
\newtheorem*{solution*}{Solution}

\newtheorem{lemma}{Lemma}

\newcommand{\hint}{\noindent \textbf{Hint}:\xspace}

\usepackage{hyperref}

\newcommand{\epssub}{\delta}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\sA}{\mathcal{A}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}


\begin{document}

\begin{center}
{\Large \textbf{CMPUT 605: Theoretical Foundations of Reinforcement Learning, Winter 2023\\ Homework \#\hwnumber}}
\end{center}

\section*{Instructions}
\textbf{Submissions}
You need to submit a single PDF file, named {\tt p0\hwnumber\_<name>.pdf} where {\tt <name>} is your name.
The PDF file should include your typed up solutions (we strongly encourage to use pdf\LaTeX). 
Write your name in the title of your PDF file.
We provide a \LaTeX template that you are encouraged to use.
To submit your PDF file you should send the PDF file via private message to Vlad Tkachuk on Slack before the deadline.

\textbf{Collaboration and sources}
Work on your own. You can consult the problems with your classmates, use books
or web, papers, etc.
Also, the write-up must be your own and you must acknowledge all the
sources (names of people you worked with, books, webpages etc., including class notes.) 
Failure to do so will be considered cheating.  
Identical or similar write-ups will be considered cheating as well.
Students are expected to understand and explain all the steps of their proofs.

\textbf{Scheduling}
Start early: It takes time to solve the problems, as well as to write down the solutions. Most problems should have a short solution (and you can refer to results we have learned about to shorten your solution). Don't repeat calculations that we did in the class unnecessarily.

\vspace{0.3cm}

\textbf{Deadline:} February 12 at 11:55 pm

\newcommand{\cM}{\mathcal{M}}
\newcommand{\nS}{\mathrm{S}}
\newcommand{\nA}{\mathrm{A}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ip}[1]{\langle #1 \rangle}

\section*{Problems}

\subsection*{Union bounds}
\begin{question}
Let $A_1,\dots,A_n$ be events of a probability space $(\Omega,\cF,\bbP)$. Note that finite (and actually discrete) sets are always equipped with the discrete $\sigma$-algebra (power set) unless otherwise specified.
Show that the following hold:
\begin{enumerate}
\item Show that for any random variable $I$ taking values in $[n]$, $A_I$, which is naturally defined as $$A_I = \{ \omega\in \Omega\,:\, \omega \in A_{I(\omega)} \},$$ is an event.
\points{5}
\item Show that there exist a random variable $I$ taking values in $[n]$, such that $\Prob{A_I} = \Prob{\cup_{i=1}^n A_i}$.
\points{10}
\item Show that the first two claims hold even if $I$ takes values in $\{1,2,\dots\}$ and $(A_i)_{i=1,2,\dots}$ is a countably infinite sequence of events. (It suffices to explain which parts of the solution to the first two questions need to be changed.)
\points{5}
\end{enumerate}
\tpoints{}
\end{question}
\begin{solution*}
\mbox{}

\begin{enumerate}
\item
We claim that 
\begin{align}
A_I = \cup_{i\in [n]} (\{ I=i \} \cap A_i)\,.
\label{eq:aid}
\end{align}
Call the set on the LHS $B$.
Now, if $\omega\in A_I$, then $\omega\in A_{I(\omega)}$. Let $i=I(\omega)$. 
Then $\omega \in \{I=i\}$ and $\omega \in A_i$. Hence, $\omega \in \{I=i\} \cap A_i$, and also $\omega \in B$.
Now, for every $i\in [n]$, $\{I=i\} \cap A_i$, the intersection of two events is an event (here, $\{I=i\}$ is an event, because $I$ is a random variable). The countable union of events is also an event, hence $B$ is an event.
\item 
Let $I(\omega) = n$ if $\omega\not\in \cup_i A_i$. Otherwise, let $I(\omega) = \min\{ i\in [n]\,:\, \omega\in A_i \}$. We claim that $I$ is a random variable.
For $A\subset \Omega$, let $\chi_A$ be the characteristic (indicator) function of $A$: $\chi_A(\omega)=1$ if $\omega\in A$ and $\chi_A(\omega)=0$ otherwise.
As it is immediate from the definition of random variables, $\chi_A$ is a random variable.
Now note that 
$$
I = \min( J_1,\dots,J_n, n)
$$
where for $i\in [n]$,  $J_i = i \chi_{A_i} + (n+1) \chi_{A_i^c}$. Since the complement of an event is an event and linear combination of random variables gives random variables, $J_i$ for $i\in [n]$ are random variables. Constant functions are also random variables. The minimum of random variables is a random variable, too. Hence, $I$ is a random variable.

Now, clearly, $A_I \subset \cup_{i\in [n]} A_i$ (this follows directly \eqref{eq:aid}).
To show the reverse, assume that $\omega \in \cup_{i\in [n]} A_i$. Then, $\omega\in A_i$ for some $i\in [n]$. Let $i$ be the smallest index for which $\omega\in A_i$. Then, by its definition, $I(\omega)=i$ and thus $\omega \in \{I=i\} \cap A_i \subset A_I$ by \eqref{eq:aid}.

Since $A_I = \cup_{i\in [n]} A_i$, they have the same probability.

\item 
  The first solution does not need to be changed, except for the obvious replacement of $[n]$ with $\mathbb{N}$.

  The second solution will need to be updated. Specifically, $I$ can no longer be shown to be a random variable by using the alternate definition of  
  $$
  I = \min( J_1,\dots,J_n, n),
  $$
  since $n$ can be arbitrarily large now.

  To fix this problem we first let $I(\omega) = 1$ if $\omega\not\in \cup_i A_i$ and now we will show that $I$ must be a random variable by showing that it satisfies the definiton of a measurable map.
  We have that $I: \Omega \to \mathbb{N}$ and we claim that for any $b \in P(\mathbb{N})$ ($P(\mathbb{N})$ is the power set of $\mathbb{N}$) that $I^{-1}(b) \in \mathcal{F}$.
  Note that $P(\mathbb{N})$ is a valid $\sigma$-algebra on the set $\mathbb{N}$ and is the largest possible $\sigma$-algebra on the set $\mathbb{N}$.
  Thus, if we can show that $I$ is a $\mathcal{F}/P(\mathbb{N})$ measurable map, then we have shown that $I$ is also a $\mathcal{F}/\mathcal{G}$ measurable map for any $\mathcal{G}$ that is also a $\sigma$-algebra on $\mathbb{N}$. 
  Since, for any $c \in \mathcal{G}$ we know that $c \in P(\mathbb{N})$.
  To show that $I^{-1}(b) \in \mathcal{F}$ for any $b \in P(\mathbb{N})$ it will be sufficient to show that $I^{-1}(d) \in \mathcal{F}$ for any $d \in \mathcal{D}$, where $\mathcal{D}$ is a generator of $P(\mathbb{N})$. 
  This is true due to the well known fact that the pre-image of set functions preserves set operations.
  More precisely: for a set function $F: \mathbb{X} \to \mathbb{Y}$ and $B, B_i \subset \mathbb{Y}, \ i \in \mathbb{N}$ we have that
  $$F^{-1}(\cup_i B_i) = \cup_i F^{-1}(B_i),$$
  $$F^{-1}(\mathbb{Y} \backslash B) = \mathbb{X} \backslash F^{-1}(B).$$
  Thus, the pre-images of elements of a generator can be used to construct the pre-image of any element in the $\sigma$-algebra generated by the generator.
  The generator of $P(\mathbb{N})$ we choose is $\mathcal{D} = \{ \{1\}, \{2\}, \dots \}$.
  It is clear that $I^{-1}(i) = A_i \backslash \cup_{k=1}^{i-1} A_i$ for any $i \in \mathcal{D} \backslash \{1\}$, and $I^{-1}(\{1\}) = A_1 \cup \left(\cup_i A_i\right)^c$.
  Thus, since a $\sigma$-algebra is closed under countable unions, intersections and compliments (note that set subtraction can be written using intersection and complimentation), and $A_i \in \mathcal{F}, \ \forall i \in \mathbb{N}$, we have that $I^{-1}(i) \in \mathcal{F}$. 
  Showing that $I$ is a random variable (measurable map).
  No further changes need to be made.

\end{enumerate}
\end{solution*}

\subsection*{Online planning revisited}
In the next problem we consider the variant of online planner that uses a fresh sample in each call of function $q$.
In particular, consider the following algorithm:

\begin{enumerate}
\item {\tt define q(k,s):}
\item {\tt if k = 0 return [0 for a in A] \# base case}
\item {\tt return [ r(s,a) + gamma/m * sum( [max(q(k-1,s')) for s' in C(k,s,a)] ) for a in A ]}
\item {\tt end}
\end{enumerate}

Here, the lists {\tt C(k,s,a)}, which in what follows will be denoted by $C_k(s,a)$ are as usual: They are created independently of each other for each $(s,a)$ and $k$ and they have $m$ mutually independent elements, sampled from $P_a(s)$.
In particular, $C_k(s,a) = [S_1'(k,s,a), \dots, S_m'(k,s,a)]$ where $(S_i'(k,s,a))\stackrel{\textrm{iid}}{\sim} P_a(s)$.
The planner is used the same way as before: when asked for an action at state $s_0$, it returns $\arg\max_{a\in \cA} q(k,s_0)$ with an appropriate choice of $k$ (and $m$).


Let $\hat T_k: \R^{\cS \times \cA} \to \R^{\cS \times \cA}$ be defined by 
\begin{align*}
\hat T_k q (s,a) = r_a(s) + \frac{\gamma}{m} \sum_{s'\in C_k(s,a)} \max_{a'} q(s',a')\,.
\end{align*}

\begin{question}
Assume that the rewards belong to the $[0,1]$ interval.
Show that the following hold:
\begin{enumerate}
\item For $k\ge 0$, let $Q_k(s,\cdot)$ be the values returned by the call {\tt q(k,s)} with a particular value of $s$ and $k$. Show that $Q_k(s,\cdot) = \hat T_k \dots \hat T_1 \0 (s,\cdot)$.
\points{5}
\item Fix $H>0$. Define a sequence of sets $\cS_0,\dots,\cS_H$ with $|\cS_h| = O( (mA)^h)$ and $\cS_0 = \{s_0\}$ such that with $\delta_h = \norm{Q_h - q^*}_{\cS_{H-h}}$, the following hold for any $0\le h \le H$:
\begin{enumerate}[(a)]
\item If also $h>0$, $\delta_h \le \gamma \delta_{h-1} + \norm{ \hat T_h q^* - q^* }_{\cS_{H-h}}$;
\points{5}
\item If also $h<H$, $\cS_{H-h}$ is a function of $C_H$, \dots, $C_{h+1}$ only (and is not a function of $C_{h},\dots,C_1$).
\points{5}
\end{enumerate}
\item Show that with probability $1-\zeta$, $\norm{ \hat T_h q^* - q^* }_{\cS_{H-h}}\le \frac{1}{1-\gamma} \sqrt{ \frac{\log(2|\cS_{H-h}||A|/\zeta)}{2m} }$\,.
\points{10}
\item Let $\pi$ be the policy induced by the modified planner. Give a bound on the suboptimality of $\pi$ (make it as tight as you can using the usual tools).
\points{10}
\item Compare the bound to the one we obtained for the case when the same sets are used in the algorithm throughout.
\points{5}
\item Bound the computational complexity of the algorithm; argue why one would call this the ``sparse lookahead tree approach''.
\points{5}
\end{enumerate}
\tpoints{}
\end{question}
\begin{solution*}
\mbox{}

\begin{enumerate}
\item We will show the result $Q_k(s,\cdot) = \hat T_k \dots \hat T_1 \0 (s,\cdot)$ by induction on $k$.
First, the base case with $k=0$
\begin{align*}
  & Q_0(s, \cdot) = \text{{\tt q(0, s)}} = \0. & \text{Where $\0$ is a $|\cA|$ length vector of zeros} \\
\end{align*}
Now, assume that ${\tt q(k-1, s)} = Q_{k-1}(s,\cdot) = \hat T_{k-1} \dots \hat T_1 \0 (s,\cdot)$ holds. We show that $Q_{k}(s,\cdot) = \hat T_{k} \dots \hat T_1 \0 (s,\cdot)$ holds
\begin{align*}
  & Q_{k}(s, \cdot) = \tt q(k, s) \\
  &= \text{\tt [ r(s,a) + gamma/m * sum( [max(q(k-1,s')) for s' in C(k,s,a)] ) for a in A ]} \\
  &= r_a(s) + \frac{\gamma}{m} \sum_{s' \in C_{k}(s,a)} \max_{a'} Q_{k-1}(s', a'), \ \forall a \in \cA \\
  &= r_a(s) + \frac{\gamma}{m} \sum_{s' \in C_{k}(s,a)} \max_{a'} \left( \hat T_{k-1} \dots \hat T_1 \0 (s', a') \right), \ \forall a \in \cA \quad \text{By inductive assumption} \\
  &= \hat T_k \hat T_{k-1} \dots \hat T_1 \0 (s, a), \ \forall a \in \cA \\
  &= \hat T_k \dots \hat T_1 \0 (s, \cdot)
\end{align*}
\item As usual, let $C_k(s) = \cup_a C_k(s,a)$.
We let $\cS_1 = \cup_{s\in \cS_0} C_H(s) (=C_H(s_0))$ and, more generally,
for $i>0$, 
 $\cS_i  = \cup_{s\in \cS_{i-1}} C_{H-i+1}(s)$.
\begin{enumerate}[(a)]
\item Let $h>0$. 
%Use $\hat T_{h:}$ as an abbreviation to $\hat T_h \hat T_{h-1} \dots \hat T_1$.
To show 
$\delta_h \le \gamma \delta_{h-1} + \norm{ \hat T_h q^* - q^* }_{\cS_{H-h}}$,
 note that, by the triangle inequality and the definition of $\hat T_h$,
 \begin{align*}
\delta_h 
& = \norm{Q_h-q^*}_{\cS_{H-h}}\\
& = \norm{ \hat T_h Q_{h-1}  - \hat T_h q^*}_{\cS_{H-h}} + 
       \norm{ \hat T_h q^* - q^*}_{\cS_{H-h}}\,.
\end{align*}
For the first term,
\begin{align*}
\norm{ \hat T_h  Q_{h-1} - \hat T_h q^*}_{\cS_{H-h}}
& \le
\frac{\gamma}{m} \max_{s\in \cS_{H-h}, a\in \cA} 
 \sum_{s'\in C_h(s,a)} | M Q_{h-1} (s') - v^*(s') | \\
& \le
\gamma\, \max_{s\in \cS_{H-h}, a\in \cA} 
\max_{s'\in C_h(s,a)}
| M Q_{h-1} (s') - v^*(s') | \\
& =
\gamma\,
\max_{s\in \cS_{H-h+1}} 
| M Q_{h-1} (s) - v^*(s) | \\
& \le
\gamma\,
\norm{ Q_{h-1} (s) - q^*(s) }_{\cS_{H-h+1}}\,.
\end{align*}
\item This follows by induction starting with $h=H-1$. 
Clearly, $\cS_1$ is a function of $C_H$ only.
Assume that  we already established that for
$0<h<H$, $\cS_{H-h}$ is a function of $C_H, \dots, C_{h+1}$ only.
Then,
by its definition,
 $\cS_{H-(h-1)} = \cS_{H-h+1} = \cup_{s\in \cS_{H-h}} C_{H-(H-h)}(s) = \cup_{s\in \cS_{H-h}} C_h(s)$.
And now, by the induction hypothesis, the claim follows:
$\cS_{H-(h-1)}$ is a function of $C_H, \dots, C_{h+1}$ and $C_h$ only.
\end{enumerate}
 
\item Fix $h$.
For a fixed state $s \in \mathcal{S}$ and a fixed action $a \in \mathcal{A}$, w.p. at least $1 - \zeta$,
  \begin{align*}
    \overbrace{\left| \hat{T}_h q^*(s, a) - q^*(s, a) \right|}^{\Delta_h(s,a):=}
    &= \gamma \left| \frac{1}{m} \sum_{s' \in C_h(s, a)} v^*(s') - \gamma \langle P_a(s), v^* \rangle \right| \\
    &< \gamma \|v^*\|_\infty \sqrt{\frac{\log(2 / \zeta)}{2m}} \tag*{(using Hoeffding's inequality)} \\
    &\leq \underbrace{\frac{\gamma}{1 - \gamma} \sqrt{\frac{\log(2 / \zeta)}{2m}}}_{=:f(\zeta)}. \tag*{(since rewards lie in $[0, 1]$)}
  \end{align*}

We claim that w.p. at least $1 - \zeta$,
\begin{align}
  \left| \hat{T}_h q^*(s, a) - q^*(s, a) \right| < \frac{\gamma}{1 - \gamma} \sqrt{\frac{\log(2 \mathrm{A} |\mathcal{S}_{H-h}|/ \zeta)}{2m}}, \quad \text{for all } s\in \cS_{H-h}, a\in \cA.
  \label{eq:tdpl}
\end{align}
To prove this, for $\cS'\subset \cS$ nonempty and
$s\in \cS,a\in \cA$ we let
\begin{align*}
F_{s,a}(\cS') = \{ \Delta_h(s,a)\ge f(\zeta/(\nA|\cS'|)) \}\,.
\end{align*}
Display \eqref{eq:tdpl} is equivalent to 
\begin{align*}
\Prob{ \cup_{s\in \cS_{H-h},a\in \cA} F_{s,a}(\cS_{H-h}) } \le \zeta\,.
\end{align*}
To verify this inequality we use the law of total probability:
\begin{align*}
\Prob{ \cup_{s\in \cS_{H-h},a\in \cA} F_{s,a}(\cS_{H-h}) }
&=
\sum_{\cS"\subset \cS,\cS'\ne\emptyset}
\Prob{ \cup_{s\in \cS_{H-h},a\in \cA} F_{s,a}(\cS_{H-h}), \cS_{H-h}=\cS' } \\
&=
\sum_{\cS"\subset \cS,\cS'\ne\emptyset}
\Prob{ \cup_{s\in \cS',a\in \cA} F_{s,a}(\cS'), \cS_{H-h}=\cS' } \\
&\stackrel{(*)}{=}
\sum_{\cS"\subset \cS,\cS'\ne\emptyset}
\Prob{ \cup_{s\in \cS',a\in \cA} F_{s,a}(\cS')} \Prob{ \cS_{H-h}=\cS' }   \\
&\le
\zeta \sum_{\cS"\subset \cS,\cS'\ne\emptyset}
\Prob{ \cS_{H-h}=\cS' }    = \zeta\,,
\end{align*}
where the 
equality marked with $(*)$ used that
by part (b) of Q2 and the definitions,
$\cS_{H-h}=\cS'$ and $\cup_{s\in \cS',a\in \cA} F_{s,a}(\cS')$ are independent (the latter only depends on $C_h$, the former only depends on $C_H,\cdots,C_{h+1}$, which are independent),
and
the 
last inequality follows from a union bound.
Indeed, for $\cS'\subset \cS$ nonemtpy,
\begin{align*}
\Prob{\cup_{s\in \cS',a\in \cA} F_{s,a}(\cS')}
\le
\sum_{s\in \cS',a\in \cA} \Prob{ F_{s,a}(\cS')}
\le |\cS'| \nA \, \frac{\zeta}{\nA|\cS'|} = \zeta\,.
\end{align*}

Now, from \eqref{eq:tdpl} 
we get that w.p. at least $1 - \zeta$,
  \begin{align*}
    \|\hat{T}_h q^* - q^*\|_{\mathcal{S}_{H-h}} &= \max_{s \in \mathcal{S}_{H-h} } \max_{a \in \mathcal{A}} \left| \hat{T}_h q^*(s, a) - q^*(s, a) \right| \\
    &\leq \frac{\gamma}{1 - \gamma} \sqrt{\frac{\log(2 \mathrm{A} |\mathcal{S}_{H-h}|/ \zeta)}{2m}} \\
    & \leq \frac{1}{1 - \gamma} \sqrt{\frac{\log(2 \mathrm{A} |\mathcal{S}_{H-h}|/ \zeta)}{2m}}.
  \end{align*}
  
\item We first use the recurrence relation $\delta_h \leq \gamma \delta_{h-1} + \|\hat{T}_h q^* - q^*\|_{\cS_{H-h}}$ from Q2, to obtain an expression for $\delta_H := \|Q_H - q^*\|_{\cS_0} := \max_{a} |Q_H(s_0, a) - q^*(s_0, a)|$ as follows
  \begin{align*}
    \delta_H &\leq \gamma \delta_{H-1} + \|\hat{T}_H q^* - q^*\|_{\cS_{0}} \\
    &\leq \gamma^2 \delta_{H-2} + \gamma \|\hat{T}_{H-1} q^* - q^*\|_{\cS_{1}} + \|\hat{T}_H q^* - q^*\|_{\cS_{0}} \\
    & \;\; \vdots \\
    &\leq \gamma^H \delta_0 + \sum_{k=0}^{H-1} \gamma^k \|\hat{T}_{H-k} q^* - q^*\|_{\cS_{k}} \\
    &\leq \frac{\gamma^H}{1 - \gamma} + \sum_{k=0}^{H-1} \gamma^k \|\hat{T}_{H-k} q^* - q^*\|_{\cS_{k}}. \tag*{(since $\delta_0 := \|Q_0 - q^*\|_{\cS_H} = \|q^*\|_{\cS_H} \leq \frac{1}{1 - \gamma}$)}
  \end{align*}

  Using the result from Q3 with the fact that $|\cS_k| = (m\mathrm{A})^k$, we get that for a fixed $k$, w.p. $1 - \zeta$, $\|\hat{T}_{H-k} q^* - q^*\|_{\cS_{k}} \leq \frac{1}{1 - \gamma} \sqrt{\frac{\log(2 \mathrm{A} (m\mathrm{A})^{k} / \zeta)}{2m}}$. Now we can employ union bound over the index $0 \leq k \leq H-1$, in the equation for $\delta_H$ given above, to get w.p. $1 - \zeta$
  \begin{align*}
    \delta_H &= \max_{a} |Q_H(s_0, a) - q^*(s_0, a)| \leq \frac{\gamma^H}{1 - \gamma} + \frac{1}{1 - \gamma} \sum_{k=0}^{H-1} \gamma^k \sqrt{\frac{\log(2 H \mathrm{A} (m\mathrm{A})^{k} / \zeta)}{2m}} =: \Delta(m, H, \zeta),
  \end{align*}

  where the extra $H$ comes in the numerator comes from union bound over the index $0 \leq k \leq H-1$.\footnote{It might be possible to obtain a tighter bound by using separate $\zeta_k = x_k \zeta$, with $x_k$s found by solving the optimization problem $\min \sum_{k=0}^{H-1} \sqrt{\log(e_k / x_k)}$ subject to $\sum_{k=0}^{H-1} x_k = 1$. But maybe $x_k = 1/H$ is a good enough solution; at least it's super simple! Another choice could be $x_k = e_k \big/ \sum_{i=1}^{H} e_i$.}

  From above equation we get that the policy induced by the local planner $\pi(s_0) = \arg \max_a Q_H(s_0, a)$ is $2 \Delta(m, H, \zeta)$-optimizing. Then using policy error bound II from Lecture 6, we get that $\pi$ is $\varepsilon(m, H, \zeta)$-optimal with $\varepsilon(m, H, \zeta)$ defined as
  \begin{align*}
    \frac{2 \Delta(m, H, \zeta) + 2 \zeta \|q^*\|_\infty}{1 - \gamma} &\leq \frac{2}{(1 - \gamma)^2} \left[ \gamma^H + \sum_{k=0}^{H-1} \gamma^k \sqrt{\frac{\log(2 H \mathrm{A} (m\mathrm{A})^{k} / \zeta)}{2m}} + \zeta \right] =: \varepsilon(m , H, \zeta).
  \end{align*}

\item The bound given in the lecture 6 was $\epsilon_\text{lec}(m,H,\zeta):=\frac{2}{(1-\gamma)^2} \left[\gamma^H + \frac{1}{1-\gamma} \sqrt{ \frac{\log\left(2n\mathrm{A}/\zeta\right)}{2m} } + \zeta \right]$ with $n = (m\mathrm{A})^H$. Therefore, we need to compare the two terms $T_1 = \sum_{k=0}^{H-1} \gamma^k \sqrt{\frac{\log(2 H \mathrm{A} (m\mathrm{A})^{k} / \zeta)}{2m}}$ and $T_2 = \frac{1}{1-\gamma} \sqrt{ \frac{\log(2\mathrm{A} (m\mathrm{A})^H /\zeta)}{2m} }$. It is likely that $T_1 \leq T_2$ in general, since for all but large $k$, $H (m\mathrm{A})^k \ll (m\mathrm{A})^H$. Thus, this bound is tighter than that given in the lecture. In fact, a quick calculation gives that one saves a factor of $H$ on setting $m$ this way.

  We could obtain a bound, similar to the one obtained here, in the lecture if we don't use the relaxation $\| \hat T q^* - q^* \|_{\mathcal{S}_{H-h}} \leq \| \hat T q^* - q^* \|_{\mathcal{S}_{H-1}}$ while deriving the recurrence for $\delta_h$  (see lecture 6 notes) and in fact the bound then would save (an insignificant) $H$ in the logarithm.

\item It is straightforward to see that the computational complexity of the algorithm is $O((m\mathrm{A})^H)$. If we use the result $\varepsilon(m, H, \zeta) \leq \epsilon_\text{lec}(m, H, \zeta)$, hypothesized in Q5, then the computation complexity is the same as given in lecture 6 notes with $m \geq m^*$ (Eq. 8 in the lecture 6 notes). A tighter analysis should also be possible.

Paraphrasing from Kearns, Mansour, \& Ng (2002), this algorithm is based on the idea of sparse sampling. As we showed above, a randomly sampled look-ahead tree that covers only a fraction (given by the value $m^*$) of the full look-ahead tree suffices to compute near-optimal actions from any state $s_0$ of an MDP. Therefore, this approach is called a sparse-lookahead tree approach. Here, we can think of the computation as building out a lookahead tree of depth $H$ from $s_0$ and then using this tree to back-propagate action-values using value iteration.
\end{enumerate}
\end{solution*}


\section*{Tightness of performance bounds of greedy policies}

Error bounds for greedy policies are at the heart of many of the upper bounds we obtained.
Here you will be asked to show that these bounds are unimprovable.
For example, in
\href{http://rltheory.github.io/lecture-notes/planning-in-mdps/lec6/}{Lecture 6},
the following is stated in
Part II of the ``Policy error bound - I.'' lemma:
\begin{lemma}
Let $\pi$ be a memoryless policy and choose a function $q:\mathcal{S}\times\mathcal{A} \to \mathbb{R}$ and $\epsilon\ge 0$. Then,
if $\pi$ is greedy with respect to $q$ then
\begin{align*}
v^\pi \ge v^* - \frac{2\|q-q^*\|_\infty}{1-\gamma} \boldsymbol{1}\,.
\end{align*}
\end{lemma}
\begin{question}
Show that for any $\gamma\in [0,1)$ and $\varepsilon>0$ there is a finite
discounted MDP $M=(\cS,\cA,P,r,\gamma)$ and $q:\cS \times \cA \to \R$ such that the following hold:
\begin{enumerate}
\item $\norm{q-q^*}_\infty  =\varepsilon$;
\item There is policy $\pi$ that is greedy with respect to $q$ such that $\|v^\pi-v^*\|_\infty = \frac{2\varepsilon}{1-\gamma}$.
\end{enumerate}
\tpoints{10}
\end{question}
\begin{solution*}
% Source: Ronald Williams, Leemon C. Baird. 1993. “Tight Performance Bounds on Greedy Policies Based on Imperfect Value Functions.” http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.35.3281.
The MDP will have a single state, call it $s$ (i.e., $\cS = \{s\}$) and two actions, say, $\cA = \{1,2\}$.
Since there is only a single state, of course
$p_a(s|s)=1$ for both actions $a$.
Let
\begin{align*}
0\le r_1(s)\le r_2(s)=1\,.
\end{align*}
Then
\begin{align*}
v^*(s) = \frac{1}{1-\gamma}\,.
\end{align*}
For the policy $\pi$ that chooses action $1$ in state $s$, we have
\begin{align*}
v^\pi(s)=\frac{r_1(s)}{1-\gamma}\,.
\end{align*}
Hence,
\begin{align*}
\norm{v^\pi-v^*}_\infty=\frac{1-r_1(s)}{1-\gamma}
\end{align*}
and thus
$\norm{v^\pi-v^*}_\infty=\frac{2\varepsilon}{1-\gamma}$
if $r_1(s) = 1-2\varepsilon$.
Hence, choose this for the value of $r_1(s)$.
Thus,
\begin{align*}
q^*(s,1) &= r_1(s) + \gamma \frac{1}{1-\gamma} = \frac{1}{1-\gamma} - 2 \varepsilon\,,\\
q^*(s,2) &= \frac{1}{1-\gamma}
\end{align*}
and hence if
\begin{align*}
q(s,1) = q^*(s,1)+\varepsilon \text{ and }
q(s,2) = q^*(s,2)-\varepsilon
\end{align*}
then $q(s,1)=q(s,2) = \frac{1}{1-\gamma}-\epsilon$, $\norm{q-q^*}_\infty = \varepsilon$
and policy $\pi$ is greedy with respect to $q$ (because any policy is greedy with respect to $q$ as it assigns the same value for both actions). By our previous argument, $\norm{v^\pi-v^*}_\infty = 2\varepsilon/(1-\gamma)$, thus, finishing the proof.
\qed\par\smallskip\hrule
\end{solution*}


\bigskip
\bigskip

\noindent
\textbf{
Total for all questions: \arabic{DocPoints}}.
Of this, 10 are bonus marks. 
Your assignment will be marked out of 65.

\end{document}




