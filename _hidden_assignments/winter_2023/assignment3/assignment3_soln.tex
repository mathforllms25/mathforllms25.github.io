% !TEX encoding = UTF-8 Unicode
\documentclass{article}
\newcommand{\hwnumber}{3}

\newcommand{\norm}[1]{\| #1 \|}
\newcommand{\abs}[1]{| #1 |}


\usepackage{fullpage,amsthm,amsmath,amssymb}
\usepackage{algorithm,algorithmic}
\usepackage{mathtools}
\usepackage{bbm,bm}
\usepackage{enumerate}
\usepackage{cancel}
\usepackage{xspace}
\usepackage[textsize=tiny,
%disable
]{todonotes}
\newcommand{\todot}[1]{\todo[color=blue!20!white]{T: #1}}
\newcommand{\todoc}[1]{\todo[color=orange!20!white]{Cs: #1}}
\usepackage[colorlinks,citecolor=blue,urlcolor=blue,linkcolor=black]{hyperref}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\usepackage[capitalize]{cleveref}


\usepackage{comment}

\newcommand{\cE}{\mathcal{E}}
\newcommand{\oneb}[1]{\mathbb{I}_{#1}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\cZ}{\mathcal{Z}}
\newcommand{\cX}{\mathcal{X}}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator*{\Exp}{\mathbf{E}}
\DeclareMathOperator*{\1}{\mathbbm{1}}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\E}{\mathbb E}
\newcommand{\bbP}{\mathbb P}
\newcommand{\V}{\mathbb V}
\renewcommand{\P}[1]{P\left\{ #1 \right\}}
\newcommand{\Prob}[1]{\mathbb{P}( #1 )}
\newcommand{\real}{\mathbb{R}}
\renewcommand{\b}[1]{\mathbf{#1}}
\newcommand{\EE}[1]{\E[#1]}
\newcommand{\bfone}{\1}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\0}{\mathbf{0}}
\newcommand{\one}[1]{\mathbb{I}\{#1\}}
\usepackage{xifthen}

% total number of points that can be collected
\newcounter{DocPoints} % counter reset to zero upon creation

% counting points per question (not user facing)
\newcounter{QuestionPoints} % counter reset to zero upon creation

% Points for a subquestion of a question;
% Adds the points to the total for the question and the document.
\newcommand{\points}[1]{%
	\par\mbox{}\par\noindent\hfill {\bf #1 points}%
	\addtocounter{DocPoints}{#1}
	\addtocounter{QuestionPoints}{#1}
}
% Points for a question; call with no params if the question
% had subquestions. In this case it prints the total for the question (see \points).
% Otherwise call with the points that the question is worth.
% In this case, the total is added to the document total.
% It is a semantic error to call this with a non-empty parameter
% when a question had subquestions with individual scores.
\newcommand{\tpoints}[1]{        %
	\ifthenelse{\isempty{#1}}%
	{%
	}%
	{%
		\addtocounter{DocPoints}{#1}
		\addtocounter{QuestionPoints}{#1}
	}													 %
	\par\mbox{}\par\noindent\hfill {Total: \bf \arabic{QuestionPoints}\xspace points}\par\mbox{}\par\hrule\hrule
	\setcounter{QuestionPoints}{0}
}
\newcommand{\tpoint}[1]{
	\tpoints{#1}
}

\theoremstyle{definition}
\newtheorem{question}{Question}
\newtheorem{assumption}{Assumption}
\newtheorem*{assumption*}{Assumption}

\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem*{remark*}{Remark}
\newtheorem{solution}{Solution}
\newtheorem*{solution*}{Solution}

\theoremstyle{theorem}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\excludecomment{solution}
%\excludecomment{solution*}

\newcommand{\hint}{\noindent \textbf{Hint}:\xspace}


\usepackage{hyperref}

\newcommand{\epssub}{\delta}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\sA}{\mathcal{A}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}


\begin{document}

\begin{center}
{\Large \textbf{CMPUT 605: Theoretical Foundations of Reinforcement Learning, Winter 2023\\ Homework \#\hwnumber}}
\end{center}

\section*{Instructions}
\textbf{Submissions}
You need to submit a single PDF file, named {\tt p0\hwnumber\_<name>.pdf} where {\tt <name>} is your name.
The PDF file should include your typed up solutions (we strongly encourage to use pdf\LaTeX). 
Write your name in the title of your PDF file.
We provide a \LaTeX template that you are encouraged to use.
To submit your PDF file you should send the PDF file via private message to Vlad Tkachuk on Slack before the deadline.

\textbf{Collaboration and sources}
Work on your own. You can consult the problems with your classmates, use books
or web, papers, etc.
Also, the write-up must be your own and you must acknowledge all the
sources (names of people you worked with, books, webpages etc., including class notes.)
Failure to do so will be considered cheating.
Identical or similar write-ups will be considered cheating as well.
Students are expected to understand and explain all the steps of their proofs.

\textbf{Scheduling}
Start early: It takes time to solve the problems, as well as to write down the solutions. Most problems should have a short solution (and you can refer to results we have learned about to shorten your solution). Don't repeat calculations that we did in the class unnecessarily.

\vspace{0.3cm}

\textbf{Deadline:} March 12 at 11:55 pm

\newcommand{\cM}{\mathcal{M}}
\newcommand{\nS}{\mathrm{S}}
\newcommand{\nA}{\mathrm{A}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ip}[1]{\langle #1 \rangle}


\section*{Average vs. mixed policies}
Fix policies $\pi^{(1)},\dots,\pi^{(k)}$ of some finite discounted MDP $M=(\cS,\cA,P,r,\gamma)$.
There are two ways of combining these policies with
some weights $\alpha\in \cM_1([k])$.
The first way is to choose one of the policies at random from the multinomial parameterized by $\alpha$
and then follow the resulting policy for all the time steps.
Formally, one would choose
an index $I\in [k]$ at random such that $\Prob{I=i} = \alpha_i$
and then follow the policy $\pi^{(I)}$ for whichever state one encounters.
The second way is to choose the policy to follow at random in each time step.
Call the policy that is obtained following the first method the ($\alpha$-weighted) \textbf{mixture of $\pi^{(1)},\dots,\pi^{(k)}$}.
Call the policy that is obtained following the second method the ($\alpha$-weighted)
\textbf{average of $\pi^{(1)},\dots,\pi^{(k)}$}.

Intuitively,
a distribution $\mu\in \cM_1(\cS)$ over the states and
the interconnection of a mixture policy and $M$ gives rise to a probability space $(\Omega,\cF,\PP)$ that carries the random elements
$I,S_0,A_0,S_1,A_1,\dots$ with $I\in [k]$, $S_t\in \cS$ and $A_t\in \cA$ for $t\ge 0$ and such that
for $H_t = (S_0,A_0,S_1,\dots,A_{t-1},S_t)$,
\begin{enumerate}
\item  $\mathbb{P}(S_0 = s|I) = \mu(s)$ for all $s \in \mathcal{S}$,
\item  $\mathbb{P}(A_t = a | I,H_t)
			= \pi^{(I)}_t(a | H_t)$ for all $a \in \mathcal{A}, t \geq 0$,
\item  $\mathbb{P}(S_{t+1} = s' | I, H_t, A_t) = P_{A_t}(S_t, s')$ for all $s' \in \mathcal{S}$, and
\item $\PP(I=i)=\alpha_i$ for all $i\in [k]$.
\end{enumerate}
Note that all first three criteria are modified to express that the laws that govern $S_0$, the action distribution and the next state distribution are as before even when conditioning on $I$.
A new, fourth criterion is added that expresses that
the distribution of $I$ follows the multinomial distribution with parameter $\alpha$.
That the probability distribution $\PP$ with the above properties
exists is guaranteed again by the Ianescu-Tulcea theorem.
As usual, when needed, we use $\PP_\mu$ to indicate the dependence of $\PP$ on $\mu$.

\newcommand{\N}{\mathbb{N}}
\newcommand{\cG}{\mathcal{G}}

Finally some notation:
For a probability measure $\PP$ on a measurable space $(\Omega,\cF)$ and a sub-sigma algebra $\cG$ of $\cF$, let $\PP|_{\cG}$ be the probability measure on $(\Omega,\cG)$ obtained from $\PP$ by restricting it to $\cG$: $\PP|_{\cG}(U) = \PP(U)$ for any $U\in \cG$.

\begin{question}
Unless otherwise specified let
 $\pi^{(1)},\dots,\pi^{(k)}$ be arbitrary policies of $M$ and let $\alpha\in \cM_1([k])$, $\mu \in \cM_1(\cS)$ be also arbitrary.
 Also, let $(\Omega,\cF,\PP)$ as above (we shall also use $\PP_\mu$ when the dependence on $\mu$ is important).
 Let
 $Z = (S_0,A_0,S_1,A_1,\dots)$.
Show that the following hold:
\begin{enumerate}
\item $Z$ is random element between $(\Omega,\cF)$ and $((\cS\times \cA)^{\N},\cG')$ where $\cG'$ is the product $\sigma$-algebra on $(\cS\times \cA)^{\N}$
induced by the discrete topology on $\cS \times \cA$.
\points{5}
\item
\label{q1:a3:1}
Show that there is a policy $\bar \pi$ of the MDP $M$ such that for any $\mu \in \cM_1(\cS)$,
the pushforward of $\PP_\mu$ under $Z$, $(\PP_\mu)_Z$ satisfies
\[
(\PP_\mu)_Z =\PP_\mu^{\bar \pi}
\]
where $\PP_\mu^{\bar \pi}$ is the unique probability measure on
the canonical space $((\cS\times \cA)^{\N},\cG')$
induced
by the interconnection of  $\bar \pi$ and the MDP, given the initial state distribution $\mu$.
That is, a mixture policy induces a policy $\bar \pi$ of the MDP $M$.
\points{20}
\item
Let $R=\sum_{t=0}^\infty \gamma^t r_{A_t}(S_t)$ and
let $\PP$ be as above with the choice $\mu= \delta_s$. Let $\E$ be the expectation operator
corresponding to $\PP$.
Show that $v(s)=\E[R]$ is well-defined:
That is,
for any $(\Omega,\cF,\PP)$ and $(\Omega,\cF,\PP')$ as long as $\PP$ and $\PP'$ satisfy the above four properties, $\E[R]=\E'[R]$ where $\E'$ is the expectation operator underlying $\PP'$.
\points{10}
\item
Show that $v(s) = v^{\bar \pi}(s)$.
\points{5}
\item Let $\PP_\mu^{\pi^{(i)}}$ ($\PP_{\mu}^{\bar \pi}$) be the
probability measures induced on the canonical space
$((\cS \times \cA)^{\N},\cG')$ by the initial state distribution $\mu$ and the interconnection of
$\pi^{(i)}$ (respectively, $\bar \pi$) with the MDP $M$. Show that
$\PP_{\mu}^{\bar \pi} = \sum_{i=1}^k \alpha_i \PP_{\mu}^{\pi^{(i)}}$.
\points{10}
\item Mixing is guaranteed to keep performance bounds:
if for some
$v:\cS \to \R$ and for all $i\in [k]$,
$v^{\pi^{(i)}}\ge v$ then $v^{\bar \pi}\ge v$.
\points{5}
\item Averaging is not guaranteed to keep performance bounds:
For any $\gamma>1/2$
there exists an MDP with state space $\cS$, $k\ge 2$, policies $\pi_1,\dots,\pi_k$, a function $v:\cS \to \R$ and $\alpha\in \cM_1([k])$ such that $v^{\pi_i}\ge v$ holds for all $i\in [k]$, yet if $\pi$ is the $\alpha$-average of $\pi_1,\dots,\pi_k$ then $v^\pi<v$.
\points{10}
% \item The state-wise uniform average of all deterministic ML policies and the uniform mixture of all deterministic ML policies both give the policy that is uniform over all the actions.
% \points{5}
\end{enumerate}
\hint
Recall the change-of-variables formula:
For a random element $X$ taking values in some measurable set $\cX$,
the pushforward $\PP_X$ of $X$ satisfies
\begin{align*}
\EE{ f(X) } = \int f(x) \PP_X(dx)\,.
\end{align*}
%Read the \href{https://en.wikipedia.org/wiki/Ionescu-Tulcea_theorem}{Ionescu-Tulcea theorem}. The uniqueness part should help.
Recall also that integration is linear in measures.
In particular,
for any measures $\PP_i$ and nonnegative coefficients $\alpha_i$, $i\in[k]$
and $f$ which is $(\sum_{i=1}^k \alpha \PP_i)$-integrable,
 $\int f d(\sum_{i=1}^k \alpha \PP_i) = \sum_{i=1}^k \alpha_i \int f d\PP_i$
 (this also extends to signed measures, but we won't need this extension).
\tpoints{}
\end{question}

\begin{solution*}
Let $s,a,s_0,a_0,s_1,a_1,\dots$ be an arbitrary sequence of state-actions pairs.
\begin{enumerate}
\item We need to check that for $U\in \cG'$, $Z^{-1}(U)\in \cF$.
Since $\cG'$ is a product $\sigma$-algebra, it suffices to check this for the ``simple'' cylinder sets, i.e., when $U$
is either of the form
\begin{align*}
C   & = \{ s_0 \} \times \{ a_0 \} \times \{ s_1 \} \dots \{ s_t \} \times \Omega\,, \quad \text{or, of the form}\\
C' & = \{ s_0 \} \times \{ a_0 \} \times  \{ s_1 \} \dots \{ s_t \} \times \{a_t\}\times \Omega\,.
\end{align*}
For the first case, $Z^{-1}(C) = \{S_0=s_0,A_0=a_0,S_1=s_1,\dots,S_t=s_t\}$, which is in $\cF$ because $S_0,\dots,S_t$ and $A_0,\dots,A_{t-1}$ are $\cF$-measurable.
The same holds for the second case for identical reasons, just add that $A_t$ is also $\cF$-measurable.
In this case,
$Z^{-1}(C') = \{S_0=s_0,A_0=a_0,S_1=s_1,\dots,S_t=s_t,A_t=a_t\}$.
\item
Fix $\mu$ and let $\PP=\PP_\mu$.
We show that $\PP$ satisfies the criteria that define
the probability measure $\PP_{\mu}^{\bar \pi}$ with a suitable policy $\bar \pi$.
It follows that $\PP_Z$ also satisfies these criteria (because the criteria are concerned with events in $\sigma(Z)$).
Hence, $\PP_Z = \PP_{\mu}^{\bar \pi}$ follows
by the uniqueness of the canonical probability space.
Fix any $t\ge 0$.
For the first criterion, by the tower rule,
\begin{align*}
\Prob{S_0=s} = \EE{ \Prob{S_0=s|I} } = \EE{ \mu(s) } = \mu(s)\,.
\end{align*}
The second criterion will be verified by defining $\bar \pi_t$ as
\begin{align*}
\bar \pi_t(a|h_t)=
\begin{cases}
\PP(A_t=a|H_t=h_t)\,, & \text{if } \PP(H_t=h_t)>0\,;\\
\pi_0(a)\,, & \text{otherwise}\,,
\end{cases}
\end{align*}
where $h_t = (s_0,a_0,\dots,a_{t-1},s_t)$ is arbitrary and $\pi_0$ is an arbitrary distribution over the actions.
This indeed defines a policy: $\bar \pi = (\bar \pi_t)$; $\bar \pi_t$ maps histories to distributions. Indeed,
this is clear when $\PP(H_t=h_t)=0$. Otherwise,
\begin{align*}
\MoveEqLeft\sum_{a\in \cA} \bar \pi_t(a|h_t) \\
&= \sum_{a\in \cA} \PP(A_t=a|H_t=h_t) \\
&=\PP(A_t\in \cA|H_t=h_t) =1\,.
\end{align*}
We now claim that $\bar \pi_t$ is independent of $\mu$ ($\PP$ hides its dependence on $\mu$).
Again, this is clear when $\PP(H_t = h_t)=0$ since $\pi_0$ does not depend on $\mu$.
When $\PP(H_t=h_t)>0$ we have
\begin{align*}
\bar\pi_t(a|h_t)
&= \Prob{A_t=a|H_t=h_t}\\
&= \sum_i \Prob{A_t=a|H_t=h_t,I=i} \Prob{I=i|H_t=h_t}
=
\sum_i \pi^{(i)}_t(a|h_t) \Prob{I=i|H_t=h_t}\,,
\end{align*}
where the last equality follows because if $\PP(H_t=h_t,I=i)=0$ then, by definition,
$\PP(I=i|H_t=h_t)=0$, and hence
$\Prob{A_t=a|H_t=h_t,I=i} \Prob{I=i|H_t=h_t} = 0 = \pi^{(i)}_t(a|h_t) \Prob{I=i|H_t=h_t}$.

It remains to show that $ \Prob{I=i|H_t=h_t}$ does not depend on $\mu$.
Again, this is clear when $\Prob{H_t=h_t}=0$ since in this case $ \Prob{I=i|H_t=h_t}=0$.
For the case when $ \Prob{I=i|H_t=h_t}>0$, we have
\begin{align*}
\Prob{I=i|H_t=h_t} = \frac{\Prob{H_t=h_t,I=i}}{\Prob{H_t=h_t}}\,.
\end{align*}
Based on the properties of $\PP$, with repeated conditioning, we calculate,
\begin{equation}
\begin{split}
\Prob{H_t=h_t,I=i}
&= \alpha_i\mu(s_0) \, \pi_0^{(i)}(a_0|s_0) \pi_1^{(i)}(a_1|s_0,a_0,s_1) \dots
\pi_{t-1}^{(i)}(a_{t-1}|s_0,a_0,\dots,s_{t-1}) \,\, \times \\
& \qquad  \qquad \,\,\, P_{a_0}(s_0,s_1) \dots P_{a_{t-1}}(s_{t-1},s_t)\,.
\end{split}
\label{eq:prodp}
\end{equation}
Hence,
\begin{align*}
\MoveEqLeft \Prob{I=i|H_t=h_t} =\\
& \frac{
\pi_0^{(i)}(a_0|s_0) \pi_1^{(i)}(a_1|s_0,a_0,s_1) \dots
\pi_{t-1}^{(i)}(a_{t-1}|s_0,a_0,\dots,s_{t-1}) \,\,
\cancel{\mu(s_0)P_{a_0}(s_0,s_1) \dots P_{a_{t-1}}(s_{t-1},s_t)}
}{
\sum_i \alpha_i\pi_0^{(i)}(a_0|s_0) \pi_1^{(i)}(a_1|s_0,a_0,s_1) \dots
\pi_{t-1}^{(i)}(a_{t-1}|s_0,a_0,\dots,s_{t-1}) \,\,
\cancel{\mu(s_0)P_{a_0}(s_0,s_1) \dots P_{a_{t-1}}(s_{t-1},s_t)}
}\,,
\end{align*}
which is independent of $\mu$ as required.

For the third criterion,
we have
\begin{align*}
\MoveEqLeft
\Prob{S_{t+1}=s|H_t, A_t}
 =
\EE{ \Prob{S_{t+1}=s|H_t, A_t, I} |H_t, A_t}
 =
\EE{ P_{A_t}(S_t,s)  |H_t, A_t}
 =
P_{A_t}(S_t,s)\,,
\end{align*}
where the first equality uses the tower rule, the second uses Property 2 of $\PP$, the third uses that $P_{A_t}(S_t,s)$ is a constant given $H_t, A_t$, hence it can be moved outside of the expectation (formally, $P_{A_t}(S_t,s)$ is $\sigma(H_t \times A_t)$ measurable).
Hence $\PP$ satisfies the three criteria of measures induced by the interconnection of $\bar \pi$, the MDP $M$ and the initial distribution $\mu$, finishing the proof.

\item
Noting that $R=f(Z)$ where $f$ is defined via
$f(s_0,a_0,s_1,a_1,\dots) = \sum_{t=0}^{\infty} \gamma^t r_{a_t}(s_t)$ is a measurable function from $((\cS\times\cA)^{\N}, \cG')$ to $(\R,\mathfrak{B}(\R))$,
it suffices to show that $\PP_Z = \PP'_Z$ because then, by the change-of-variables-formula,
\begin{align*}
\EE{R}=\EE{f(Z)}=\int f(z) \PP_Z(dz) = \int f(z) \PP_Z'(dz) = \E'[f(Z)] = \E'[R]\,.
\end{align*}
Now, for $U\in \cG'$ we have
\begin{align*}
\PP_Z(U) = \PP(Z\in U) = \PP'(Z\in U) = \PP'_Z(U)\,,
\end{align*}
where the second equality follows because, as it can be easily seen, equality here holds
for all simple cylinder sets $U$, hence $\PP_Z=\PP'_Z$ also holds and the proof is finished.

\item
By Part~\ref{q1:a3:1},  $\PP_Z = \PP_s^{\bar \pi}$.
Then, with $f$ as above,
\begin{align*}
v(s) = \int f(z) \PP_Z(dz) = \int f(z) \PP_s^{\bar \pi}(dz) = v^{\bar \pi}(s)\,.
\end{align*}

\item
By \cref{eq:prodp} and the construction of $\PP_{\mu}^{\pi^{(i)}}$,
\begin{align*}
\PP(H_t=h_t,I=i)
& =
\alpha_i \mu(s_0)
\prod_{j=0}^{t-1} \pi_j^{(i)}(a_j|s_0,a_0,\dots,s_j)
\prod_{j=0}^{t-1} P_{a_j}(s_j,s_{j+1}) \\
& = \alpha_i \PP_{\mu}^{\pi^{(i)}}( H_t=h_t)\,,
\end{align*}
and, similarly,
\begin{align*}
\PP(H_t=h_t,A_t=a_t,I=i)
 = \alpha_i \PP_{\mu}^{\pi^{(i)}}( H_t=h_t,A_t=a_t)\,.
\end{align*}
Summing these up for $i\in [k]$, we get
\begin{align*}
\PP(H_t=h_t)  &= \sum_{i=1}^k \alpha_i \PP_{\mu}^{\pi^{(i)}}( H_t=h_t)\,,\\
\PP(H_t=h_t,A_t=a_t)  &=  \sum_{i=1}^k \alpha_i \PP_{\mu}^{\pi^{(i)}}( H_t=h_t,A_t=a_t)\,.
\end{align*}
Since $h_t,a_t$ are arbitrary,
$\PP_Z =  \sum_{i=1}^k \alpha_i \PP_{\mu}^{\pi^{(i)}}$ (again, verifying this for simple cylinder sets).
By Part~\ref{q1:a3:1},
$\PP_Z = \PP_\mu^{\bar \pi}$.
Putting things together, we get
$\PP_\mu^{\bar \pi} = \sum_{i=1}^k \alpha_i \PP_{\mu}^{\pi^{(i)}}$.

\item With $f$ as in the previous parts,
\begin{align*}
v^{\bar \pi}(s) = \int f(z) \PP_s^{\bar \pi}(dz)
= \sum_i \alpha_i \int f(z) \PP_{s}^{\pi^{(i)}}(dz) = \sum_i \alpha_i v^{\pi^{(i)}}(s)\,.
\end{align*}
Hence, if $v^{\pi^{(i)}}\ge v$ then multiplying both sides by $\alpha_i\ge 0$,
integrating with respect to $\PP_s^{\pi^{(i)}}$ and summing up we get
$v^{\bar \pi} \ge v$.

% $\nu_\mu^\pi = \sum_i \alpha_i \nu_\mu^{\pi_i}$.
\item It is enough to consider a $2$-state, $2$-action MDP with $\cS = \cA = [2]$ such that action $i\in [2]$ sets the next state to $i$ (deterministically). Further, make staying at any of the states incur a reward of $1$, while make transitioning between the states incur a reward of zero.
Choose $k=2$. Policy $\pi_i$ uses action $i$ (moving to state $i$) everywhere.
The value of both $\pi_1$ and $\pi_2$ is above $\gamma/(1-\gamma)$. The uniform average chooses the actions at random at both states.
The value of the averaged policy $\pi$ at both states is $\frac{1}{2(1-\gamma)}$, which is lower than $\gamma/(1-\gamma)$ provided that $\gamma> 1/2$.

% \item
% This question was incorrect, it did not hold for the mixing case.
% For averaging it is trivial.

% For mixing we show a counter example.
% Our goal is to show $\mathbb{P}(A_t = a |H_t = h_t) = 1/A$ if we restrict ourselves to uniform mixtures of all deterministic "ML" policies.
% Let $\mathcal{S} = \{s_1\}$ and $\mathcal{A} = \{a_1, a_2\}$, then pick $h_t = (s_1, a_1, s_1)$.
% Only two deterministic ML policies exist, define them such that $\pi^{(1)}(a_1|s_1) = 1$ and $\pi^{(2)}(a_2|s_1) = 1$. Then we have

% \begin{align*}
% \mathbb{P}(A_1 = a_1 |H_1 = (s_1, a_1, s_1))
% &= \sum_i \mathbb{P}(A_1 = a_1 |H_1 = (s_1, a_1, s_1), I=i) \mathbb{P}(I=i| H_1 = (s_1, a_1, s_1)) \\
% &= \sum_i \pi^{(i)} (A_1 = a_1 |H_1 = (s_1, a_1, s_1)) \mathbb{P}(I=i| H_1 = (s_1, a_1, s_1)) \\
% &= \pi^{(1)} (A_1 = a_1 |H_1 = (s_1, a_1, s_1)) \mathbb{P}(I=1| H_1 = (s_1, a_1, s_1)) + \\
% & \ \ \pi^{(2)} (A_1 = a_1 |H_1 = (s_1, a_1, s_1)) \mathbb{P}(I=2| H_1 = (s_1, a_1, s_1)) \\
% &= 1 * 1 + 0 * 0 = 1 \neq 1/2
% \end{align*}

% Basically, if it is not the first time encountering a state in the trajectory then the action that that will be selected is deterministic (exactly the same action that was selected in that state the last time is was seen).
% Define $\Pi$ to be the set of all deterministic policies, and $\Pi_{a|h}$ to be the set of all deterministic policies that take action $a$ conditioned on the history $h$.
% We first note a useful result.
% $$\sum_\PP^\pi$$

% For averaging we have that

% For mixing, we have
% \begin{align*}
% \PP(A_t=a|H_t=h_t)
% & = \frac{1}{A^S} \sum_{\pi} \PP^{\pi}(A_t=a|H_t=h_t)  \\
% & = \frac{1}{A^S} \sum_{\pi} \mathbb{I}( a= \pi(s_t) )   \\
% & = \frac{1}{A^S} A^{S-1} = \frac{1}{A}\,.
% \end{align*}
\end{enumerate}
\qed\par\smallskip\hrule
\end{solution*}

\section*{Finding needles with high probability}

The high-probability needle lemma is as follows:
\begin{lemma}[High-probability needle lemma]
\label{lem:hpn}
Any algorithm that
correctly identifies the single nonzero entry in any binary array of length $k$
with probability at least $0.91$
has the property that
on some input
the expected number of queries that the algorithm uses is
at least $\Omega(k)$.
\end{lemma}

\begin{question}
Prove~\cref{lem:hpn}.
Note that the algorithms are allowed to randomize.
\tpoints{30}
\end{question}
\begin{solution*}
\newcommand{\Perm}{\mathrm{Perm}}
We give two solutions, each of which have their own merits. The idea of the first solution is rather simple:
by repeatedly running it, any algorithm that is correct with positive probability can be turned into an algorithm which is always correct at the expense of only increasing the runtime inversely proportionally to the success probability.
However,
the formal argument relies on familiarity with Wald's identity.
In contrast, the second solution is direct and elementary, but it is special to the problem at hand.

\noindent \underline{Solution 1}:
In what follows we will identify the possible inputs over $k$ element arrays with the integers $i\in [k]$.
We prove a stronger claim that for any algorithm that returns solutions that are correct with at least probability $p$,
for any $k\ge 2$, if $q_{k.i}$ is the runtime of algorithm when it is used on input $i\in [k]$,
\begin{align*}
\max_{i\in [k]} q_{k,i} \ge p \left(\frac{k+1}{2}-\frac{1}{k} \right)-1\,,
\end{align*}

Fix $k\ge 2$.
Fix any algorithm $A$.
This algorithm gives rise to an algorithm $A'$ that knows when it is correct and $A'$ uses at most one extra query compared to $A$: When $A$ stops and chooses item $I$, at the expense of at most one extra query, $A'$ can verify whether $I=i$. Thus, $A'$ will know whether it was successful and not.
Since the number of queries issued by $A$ is at best one less than that of $A'$, it suffices to show that $A'$ uses $\Omega(k)$ queries on inputs of length $k$.
Hence, in what follows, we restrict ourselves to algorithm that also output an indicator of their own success.

Let $Q\in \{0,1,\dots\}$ denote the random number of queries used and let $S\in \{0,1\}$ be the indicator whether $A$ finds the nonzero entry in its input. As agreed, we may assume that $S$ is the output of $A$.
On input $i\in [k]$, algorithm $A$ induces some distribution $P_{k,i}\in \cM_1( \{0,1,\dots\} \times \{0,1\})$ over these pairs.
Let $q_{k,i}$ be the expected number of queries used by $A$ on input $i$.
Further, by assumption, $p_{k,i}$, the probability that algorithm $A$ succeeds on input $i$ is at least $p$:
\begin{align}
p_{k,i} \ge p\,.
\label{eq:plb}
\end{align}

Let $\mathbb{P}_{k,i}$ be the probability distribution over interaction sequences of infinitely many independent runs of $A$ on input $i$.
Define $A''$ as the algorithm that runs $A$ (every time freshly initialized) until $A$ succeeds
when it returns the item returned by $A$ on it last call.
Clearly, when $A''$ stops it finds the correct item.
We claim the following: Let $i\in [k]$ be arbitrary.
\begin{enumerate}
\item If $N$ is the number of times $A''$ runs $A$, $\PP_{k,i}(N<\infty)=1$, that is, $A''$ stops with probability one;
\item Letting $Q$ be the number of queries used by $A''$,
\begin{align}
\E_{k,i}[Q]=\E_{k,i}[N] q_{k,i} \le \frac{q_{k,i}}{p}\,.
\label{eq:wald}
\end{align}
\end{enumerate}
If the above two claims are established,
it follows that $A$  is a randomized algorithms which always finds the correct entry.
Thus, by the first problem on homework $0$, for some $i\in [k]$,
\begin{align*}
\frac{k+1}{2}-\frac{1}{k} \le \E_{k,i}[Q]\,.
\end{align*}
Putting this together with \eqref{eq:wald} gives
$p(\frac{k+1}{2}-\frac{1}{k}) \le q_{k,i}$.
Thus,
\begin{align*}
\max_{i\in [k]} q_{k,i} \ge p \left(\frac{k+1}{2}-\frac{1}{k} \right)\,,
\end{align*}
finishing the proof.

It remains to establish the above two claims.
Fixing $k,i$ allows us to reduce clutter by writing
$\E$ in place of $\E_{k,i}$ and $\PP$ in place of $\PP_{k,i}$.

To prove the claims,
introduce $(Q_t,S_t)$ as the pair where $Q_t$ is the number of queries used in call $t\ge 1$ of algorithm $A$ and where $S_t\in \{0,1\}$ indicates whether this call was successful.
By construction, $( (Q_t,S_t) )_{t\ge 1}$ is an i.i.d. sequence, with common distribution $P_{k,i}$.
Also, by definition,
\begin{align*}
N = \min \{ n\ge 1\,:\, S_n =1 \}\,.
\end{align*}
As is well known, $N$ has a geometric distribution with parameter $p_{k,i}$:
$\PP(N=n)=p_{k,i}(1-p_{k,i})^{n-1}$ and $\PP(N\ge n) = (1-p_{k,i})^{n-1}$.
As $\PP(N<\infty)= 1-\lim_{n\to\infty} \PP(N\ge n) =1$, establishing the first claim.

As to the second claim, note that by definition,
\begin{align*}
Q = \sum_{n=1}^N Q_n\,.
\end{align*}
We intend to use Wald's identity to get our desired result.
To be able to use this identity, we need to check that the following are satisfied:
\begin{enumerate}
\item $(Q_n)_{n\ge 1}$ share the same finite-mean;
\item $\E[N]<\infty$;
\item $\E[ Q_n \one{N\ge n} ] = \E[Q_n] \PP(N\ge n)$ for all $n\ge 1$;
\item $\sum_{n=1}^\infty \E[ |Q_n| \one{ N \ge n } ]<\infty$.
\end{enumerate}
If these conditions hold, Wald's identity gives
\begin{align*}
\E[Q] = \E[N] \E[Q_1]\,.
\end{align*}
Then, using that $\E[Q_1] = q_{k,i}$
and that, as is well known,
\begin{align}
\E[N] = \sum_{n\ge 1} \PP(N\ge n)=\frac{1}{p_{k,i}}\,,
\label{eq:nex}
\end{align}
combined with \eqref{eq:plb} gives
\begin{align*}
\E[Q] \le \frac{q_{k,i}}{p}
\end{align*}
as required.

It remains to verify the stated conditions.
The first condition follows from the definitions (the common mean is $q_{k,i}$).
For the second condition, we already noted that $\E[N]=1/p_{k,i}$ which is finite.
For the third condition, note that $\{N\ge n \} = \{S_1=0,\dots,S_{n-1}=0\}$ whose indicator is independent of $Q_n$ (since $Q_n$ and $(S_1,\dots,S_{n-1})$ are independent). Hence,
\begin{align*}
\E[ Q_n \one{N\ge n} ]
& = \E[ Q_n \one{S_1=0,\dots,S_{n-1}=0} ]
    = \E[ Q_n ]  \E[ \one{S_1=0,\dots,S_{n-1}=0}  ]
= \E[Q_n] \PP(N\ge n)\,,
\end{align*}
as required.
The fourth condition follows from the third:
$\sum_{n\ge 1} \E[ |Q_n|\one{N\ge n}] = \sum_{n\ge 1} \E[ Q_n \one{N\ge n }]
= \sum_{n\ge 1} \E[Q_n] \PP(N\ge n) = q_{k,i}\EE{N}<\infty$.

\bigskip
\bigskip
\noindent \underline{Solution 2}:
Let $\Perm([k])$ denote the permutations on $[k]$.
WLOG we may restrict ourselves to randomized algorithms
that query the entries in a random order, say $P\in \Perm([k])$, querying first $P(1)$, then $P(2)$, etc.
Indeed, as argued in homework 0, algorithms that query entries twice or more, are dominated.
Similarly, we may assume that the algorithm stops whenever it receives $1$ as the response
or when it queried $k-1$ entries.
In general, an algorithm may also decide to stop after $M\in [k-1]$ queries were issued:
In this case, again, WLOG, we may assume
that it outputs a random element $R$ from the entries not yet queried:
$R\in \{ P(M+1),\dots,P(k)\}$.
Thus, an arbitrary, non-dominated randomizing algorithm is fully described by the joint distribution of $(P,M,R)$.

Fix now such an algorithm.
Let $C$ be the output (entry returned by the algorithm).
Further, let $Q$ be the number of queries the algorithm uses.
Thus, on instance $i\in [k]$, $C=i$ if $P^{-1}(i)\le M$,
otherwise $C=R$. (Note that $P^{-1}(i)\le M$ is equivalent to $i\in \{P(1),\dots,P(M)\}$.)
Further, on instance $i$, $Q=\min(P^{-1}(i),M)$.
Let $I\in [k]$ be a random index that is uniformly chosen, independently of the choice of $(P,M,R)$.

Let $\PP_i$ be the probability distribution induced on $(C,Q,I)$ by running algorithm on instance $i$.
Further, let $\PP$ be the probability distribution induced on $(C,Q,I)$ by running the algorithm on a random index $I\in [k]$ with a uniform distribution.
As $\PP_i(\cdot) = \PP(\cdot|I=i)$ and $I$ is uniformly distributed,
$\PP = \frac1k \sum_{i=1}^k \PP_i$. We denote by $\E_i$ the expectation operator underlying $\PP_i$, and by $\E$ the expectation operator underlying $\PP$.

Assume that the expected query cost of the algorithm is ``small'':
\begin{align*}
\max_i \E_i[Q] \le c k
\end{align*}
for $c>0$ to be chosen later,
while the algorithm is guaranteed to return the correct answer with ``high probability'':
\begin{align*}
\min_i \PP_i(C=i)\ge 0.91\,.
\end{align*}
Fix $i\in [k]$. By Markov's inequality,
\begin{align*}
\PP_i(Q>100ck)\le \frac{\E_i[Q]}{100ck} \le \frac{1}{100}\,.
\end{align*}
Hence,
\begin{align*}
\PP_i(C=i,Q\le 100ck) \ge \PP_i(C=i)-\PP_i(Q>100ck)\ge 0.91-0.01=0.9\,.
\end{align*}
Taking the average over $i=1,\dots,k$, it follows that
\begin{align*}
\PP(C=I,Q\le 100ck) \ge 0.9\,.
\end{align*}
By the tower rule,
$\PP(C=I,Q\le 100ck) = \EE{ \PP(C=I,Q\le 100ck | P,M,R) } \ge 0.9$,
from which it follows that for some $p\in \Perm([k])$, $m\in [k-1]$, $r\in [k]$
with
\begin{align*}
r\in \{ p(m+1),\dots,p(k)\}\,,
\end{align*}
it holds that
\begin{align*}
\PP(C=I,Q\le 100ck | P=p,M=m,R=r) \ge 0.9\,.
\end{align*}
Now,
\begin{align*}
\MoveEqLeft
\PP(C=I,Q\le 100ck | P=p,M=m,R=r)
 \\
& \le \PP( p^{-1}(I)\le 100ck | P=p,M=m,R=r)
+
\PP( p^{-1}(I)> 100ck,C=I,Q\le 100ck  | P=p,M=m,R=r)\\
&\le 100 c +
\PP( p^{-1}(I)> 100ck,C=I,Q\le 100ck  | P=p,M=m,R=r)\,,
\end{align*}
where the second inequality used that $I$ and $P,M,R$ are independent and that $\lceil 100ck \rceil \le 100ck$.
Considering the last term note that if $p^{-1}(I)>100ck\ge Q$ then $Q=\min(p^{-1}(I),m)=m$
and thus $C=r$.
Thus,
\begin{align*}
\MoveEqLeft
\PP( p^{-1}(I)> 100ck,C=I,Q\le 100ck  | P=p,M=m,R=r)\\
& \le
\PP( p^{-1}(I)> 100ck,I=r   | P=p,M=m,R=r)
\le
\frac{k-\lceil 100ck+1 \rceil}{k}
\le
\frac{(k- 100ck)}{k}
= 1-100c\,,
\end{align*}
where we used again the independence of $I$ and $P,M,R$.
Choosing $c=0.002$ we see that
\begin{align*}
0.9\le
\PP(C=I,Q\le 100ck | P=p,M=m,R=r)
\le 0.8\,,
\end{align*}
which is a contradiction.
Hence, with this choice of $c$ there is no algorithm with the above two properties.

\qed\par\smallskip\hrule
\end{solution*}


\subsection*{Fitted Value Iteration}
Assume that the rewards belong to the $[0,1]$ interval and fix the discount factor $\gamma$. Let $H_\gamma = 1/(1-\gamma)$.
Assume we are given a feature map $\phi: \cS \times \cA \to \R^d$ which spans $\R^d$.
Let $\cF = \{ f_\theta \,:\, 
f_\theta(s,a) = \phi(s,a)^\top \theta, \theta \in \R^d \}$ be the span of the features.
Let $C \subset \cZ:=\cS \times \cA$ be the set whose existence is guaranteed by the Kiefer-Wolfowitz theorem for the feature map $\phi$ and let $\rho: C \to [0,1]$ be the corresponding weighting function. In particular, $|C|\le d(d+1)/2$, $\sum_{z\in C} \rho(z)=1$ and with $G_\rho = \sum_{z\in C} \rho(z) \phi(z)\phi(z)^\top$, $\max_{z\in \cZ} \norm{\phi(z)}_{G_\rho^{-1}}\le \sqrt{d}$.

For $k\ge 1$, $(s,a)\in \cS \times \cA$, let $C_k(s,a) = [S_1'(k,s,a),\dots,S_m'(k,s,a)]$ be so that all the $(C_k(s,a))_{k,s,a}$ are independent of each other, and for any $k,s,a$, $S_1'(k,s,a),\dots,S_m'(k,s,a) \stackrel{\textrm{iid}}{\sim} P_a(s)$.
For $k\ge 1$ let $\hat T_k: \R^{\cS\times \cA} \to \R$ be defined by
\begin{align*}
(\hat T_k q)(s,a) = r_a(s) + \frac{\gamma}{m} \sum_{s'\in C_k(s,a)} Mq \, (s')\,.
\end{align*}
Further, let $\Pi: \R^{\cZ} \to \R^{\cZ}$ be defined by $(\Pi f)(z) = \max(\min(f(z),H_\gamma),0)$: In words, $\Pi$ truncates the values of its argument to the $[0,H_\gamma]$ interval.

Consider the following procedure, which we call fitted $q$ iteration (FQI).%
\footnote{A terrible name.}
\begin{enumerate}
\item $\theta_0 = \0$
\item {\tt for } $k=1,2,\dots,K$ {\tt do}
\item $\qquad$ $\theta_k = \argmin_{\theta\in \R^d} \sum_{z\in C} \rho(z) (f_\theta(z)-(\hat T_k \Pi f_{\theta_{k-1}})(z))^2$
\item {\tt return} $\theta_K$
\end{enumerate}

\newcommand{\epx}{\varepsilon_{\textrm{apx}}}
%Let $\epx = \sup_{\theta} \inf_{\theta'} \norm{ \Pi f_{\theta'} - T \Pi f_{\theta} }_\infty$.
Let $\epx = \sup_{\theta} \inf_{\theta'} \norm{  f_{\theta'} - T \Pi f_{\theta} }_\infty$.
\begin{question}
Prove that the following hold:
\begin{enumerate}
\item The computation cost of FQI is $O(K d^3 m A)$ and it needs $O(d^2)$ space (all in the \href{https://en.wikipedia.org/wiki/Random-access_machine}{RAM model of computation}). The query cost is $O(K d^2 m)$. Explain how you get the bounds.
\points{5}
\item Fix $k\ge 0$. 
Let $q_k = \Pi f_{\theta_k}$. For $k>0$, let $\epsilon_k:\cZ \to R$ and $\theta_k^*\in \R^d$ 
be such that 
%$T q_{k-1}=\Pi f_{\theta_k^*}+\epsilon_k$ 
$T q_{k-1}= f_{\theta_k^*}+\epsilon_k$ 
and $\norm{\epsilon_k}_\infty \le \epx$. Show that $\epsilon_k$ and $\theta_k^*$ are well-defined (i.e., they exist).
\points{10}
\item Show that for any  $k\ge 1$, $0\le \zeta\le 1$, with probability at least $1-\zeta$,
\begin{align*}
\norm{q_k - T q_{k-1}}_\infty \le (1+\sqrt{d}) \epx + \sqrt{d} H_\gamma \sqrt{\frac{\log\left(\frac{2|C|}{\zeta}\right)}{2m}}\,.
\end{align*}
\points{10}
\item Show that, on the same event as in the previous part, the policy $\pi$ that is greedy with respect to $q_K$ is $\delta$-optimal with 
\begin{align*}
\delta \le 2 H_\gamma^2
\left\{
(1+\sqrt{d}) \epx +
 \gamma^K 
+ \sqrt{d} H_\gamma \sqrt{\frac{\log\left(\frac{2|C| K}{\zeta}\right)}{2m}} \right\}\,.
\end{align*}
\points{10}
\item 
Fix $\epsilon>0$.
Argue that $K$, $m$ and $\zeta$ can be chosen
as a polynomial function of $H_\gamma,d, 1/\epsilon$
so that the {\emph expected} suboptimality of the policy $\pi$ is bounded by
$2H_\gamma^2 (1+\sqrt{d})\epx + 2\epsilon$.  Show the choices you made.
\points{5}
\item Argue that with a query, runtime and space cost that is polynomial in $H_\gamma,d, 1/\epsilon,A$, 
the procedure obtains a policy $\pi$ that is at most $\delta$-optimal with
$\delta=2H_\gamma^2 (1+\sqrt{d})\epx + 2\epsilon$.
\points{5}
\item The MDP $\cM = (\cS,\cA,P,r,\gamma)$ is called linear in $\phi$ if it holds that with some $\theta_r\in \R^d$, $r_a(s) = f_{\theta_r}(s,a)$ holds for all $(s,a)$ and if for some $\mu:\cS \to \R^d$, 
 for any $(s,a)$,
$P_a(s,s') = \ip{\phi(s,a), \mu(s')}$. Show that if $\cM$ is linear in $\phi$ then $\epx = 0$.
\points{10}
\end{enumerate}
\tpoints{}
\end{question}
\begin{solution*}
\mbox{}

\begin{enumerate}
\item 
Note that 
\begin{align}
\theta_k = G_{\rho}^{-1} \underbrace{\sum_{z\in C} \rho(z) \phi(z) Y_k(z)}_{=:B_k}\,,
\label{eq:lstk}
\end{align}
where 
$Y_k(z) = \hat T_k \Pi f_{\theta_{k-1}}(z)$.
For $z$ fixed, $Y_k(z)$ can be computed in $O(m A d)$ steps.
All $Y_k(\cdot)$ is computed in $O(|C|mA d) = O(d^3 m A)$ steps. Given these $O(d^2)$ values, $B_k\in \R^d$ can be calculated in time $O(|C|d) = O(d^3)$ and 
thus the total cost of calculating $B_k$ is $O(d^3 m A)$.
The matrix inverse $G_\rho^{-1}$ needs only to be computed once, at the cost of, say $O(d^3)$.
The cost of matrix vector multiplication is $O(d^2)$.
The total cost of calculating $\theta_k$ is dominated by $O(d^3 m A)$.
Multiply this by $K$ to get the total cost of the procedure.

For storage, one can invert a matrix in place. Besides the matrix $G_\rho^{-1}$, one needs to store only $d$-dimensional vectors.
Hence, the storage cost is $O(d^2)$.

The query complexity of calculating comes from the need to access $C_k(z)$ for $z\in C$. Hence, the query cost is $O(d^2 m)$.
Multiply this by $K$ to get the total number of queries. 
\item Choose $\theta_k^*$ 
%as the minimizer of $\theta \mapsto g(\theta):=\norm{ T q_{k-1} - \Pi f_\theta }_\infty$. 
as the minimizer of $\theta \mapsto g(\theta):=\norm{ T q_{k-1} -  f_\theta }_\infty$. 
We argue that this exists. 
%Let $V= [0,H_\gamma]^{\cS\times \cA}$.
%and let $S:\R^d \to V$ be defined by 
%$S(\theta)=\Pi f_\theta$. Note that $S$ is well-defined (the range is indeed $V$).
%Define $G = \{ \Pi f_\theta \,:\, \theta\in \R^d \}$. This is a closed set since $S$ is continuous. 
%Since $G\subset V$ and $V$ is obviously bounded, $G$ is also bounded.
%It then follows that $G$ is compact.
%Now,
%\begin{align}
%\inf_\theta 
%\norm{ T q_{k-1} - \Pi f_\theta }_\infty
%=
%\inf_{g\in G}
%\norm{ T q_{k-1} - g }_\infty\,.
%\end{align}
%Since $g \mapsto \norm{ T q_{k-1} - g }_\infty$ is continuous, $G$ is compact, the infimum in the right-hand side is taken at some point $g^*\in G$. Take $\theta_k^* \in S^{-1}(g^*)$.
Indeed, $g$ is continuous and nonnegative. Hence, there exists a sequence $(\theta_i)_i$ such that $g(\theta_i)\to \inf_\theta g(\theta)$.
Note that $G_\rho$ is full rank because $\phi$ spans $\R^d$.
There are two cases: Either $\sup_i \norm{\theta_i}_{G_\rho}$ is finite, or it is infinite.
If it is finite, by the completeness of $\R^d$, a subsequence of $\theta_i$ converges to a minimizer of $g$
by the continuity of $g$.
In the opposite case, from $\norm{\theta_i}_{G_\rho}^2 = \sum_{z\in C} \rho(z) f_{\theta_i}^2(z)$ we see that, $(f_{\theta_i}^2(z))_i$ must be unbounded for at least one $z\in C$. 
Hence, for this $z$,
\begin{align*}
g(\theta_i)=\norm{f_{\theta_i} - T q_{k-1} }_\infty \ge |f_{\theta_i}(z)|-|T q_{k-1}(z)| \,.
\end{align*}
Hence,
\begin{align*}
\limsup_{i\to\infty} g(\theta_i) \ge \limsup_{i\to\infty} |f_{\theta_i}(z)|-|T q_{k-1}(z)|  = \infty\,,
\end{align*}
which contradict to that $\limsup_{i\to\infty} g(\theta_i) = \inf_{\theta} g(\theta) \le g(0) <\infty$.

\item 
We have 
%\begin{align*}
%\norm{q_k - T q_{k-1}}_\infty 
%& =
%\norm{ \Pi f_{\theta_k} - (\Pi f_{\theta_k^*} + \epsilon_k) }_\infty
%\le
%\norm{ \Pi f_{\theta_k} - \Pi f_{\theta_k^*}}_\infty + \epx\\
%& \le
%\norm{ f_{\theta_k} - f_{\theta_k^*}}_\infty + \epx
%\leq 
%\sqrt{d} \max_{z\in C} |\epsilon(z)| + \epx\,,
%\end{align*}
%where the first equality uses the definition of $\theta_k^*$ and $\epsilon_k$, the first inequality uses the triangle inequality and that by definition $\norm{\epsilon_k}_\infty \le \epx$,
%the next inequality uses that truncating values to an interval can only decrease the max-norm distance,
\begin{align*}
\norm{q_k - T q_{k-1}}_\infty 
& =
\norm{ \Pi f_{\theta_k} - T q_{k-1}}_\infty \\
& \le
\norm{ f_{\theta_k} - (f_{\theta_k^*} + \epsilon_k) }_\infty\\
&\le
\norm{ f_{\theta_k} - f_{\theta_k^*}}_\infty + \epx\\
& \le
\norm{ f_{\theta_k} - f_{\theta_k^*}}_\infty + \epx\\
& \leq 
\sqrt{d} \max_{z\in C} |\epsilon(z)| + \epx\,,
\end{align*}
where the first equality uses the definition of $q_k$,
the next inequality uses that $T q_{k-1}\in [0,1/(1-\gamma)]$, hence dropping the truncation can only increase the values (at the same place we also used the
definition of $\theta_k^*$ and $\epsilon_k$).
The next inequality uses the triangle inequality and that by definition $\norm{\epsilon_k}_\infty \le \epx$,
and for 
%
%Since $Tq_{k-1}$ takes values in $[0,H_\gamma]$, $|q_k(z)- T q_{k-1}(z)|\le |f_{\theta_k}(z) - T q_{k-1}(z)|$ (if $f_{\theta_k}(z)$ takes values in $[0,H_\gamma]$, $f_{\theta_k}(z) = q_k(z)$; otherwise, clearly, the projection will just help to bring the projected value closer to the ``target'' which lies in this interval). Hence,
%\begin{align*}
%\norm{q_k - T q_{k-1}}_\infty \le \norm{f_{\theta_k} - (f_{\theta_k^*} + \epsilon_k)}_\infty \le \norm{f_{\theta_k} - f_{\theta_k^*}}_\infty + \epx \leq \sqrt{d} \max_{z\in C} |\epsilon(z)| + \epx\,,
%\end{align*}
%where for 
the last inequality we use an appropriately defined function $\epsilon: C \to \R$.
For the definition recall the corollary of Lecture 8 that states that $\norm{f_{\hat\theta}-f_\theta}_\infty \le \sqrt{d} \max_{z\in C} |\epsilon(z)|$ holds for $\hat\theta = G_\rho^{-1} \sum_{z\in Z} \rho(z) \phi(z) (f_\theta(z) + \epsilon(z))$.
Now, recall the definition of $\theta_k$ from \eqref{eq:lstk}. 
Writing
\begin{align*}
Y_k(z) = (T q_{k-1})(z) + \hat \epsilon(z) = f_{\theta_k^*}(z) + \hat \epsilon(z) + \epsilon_k(z)\,,
\end{align*}
where the first equality defines $\hat\epsilon(z)$, we see that above we can use $\epsilon(z) = \hat\epsilon(z) + \epsilon_k(z)$.
Now, note from Hoeffding's inequality that with probability $1-\zeta$,
\begin{align*}
\max_{z\in C} |\hat\epsilon(z)| \le H_\gamma \sqrt{\frac{\log\left(\frac{2|C|}{\zeta}\right)}{2m}}\,,
\end{align*}
where we use that $\EE{Y_k(z)|q_{k-1}}=(T q_{k-1})(z)$ and that $S_1'(k,z),\dots,S_m'(k,z)$ are independent given $q_{k-1}$, hence,
$(M q_{k-1}( S_j'(k,z))_j$ is an i.i.d. sequence, and it takes values in the interval $[0,H_\gamma]$. \todoc{this independence is not quite well explained.}
We also have
\begin{align*}
|\epsilon(z)|\le \epx + H_\gamma \sqrt{\frac{\log\left(\frac{2|C|}{\zeta}\right)}{2m}}\,,
\end{align*}
Putting everything together gives the desired claim.

\item Let $\delta_k = \norm{ q_k - q^* }_\infty$.
For $k>0$ we have
\begin{align*}
\delta_k 
\le  \norm{ q_k - T q_{k-1} }_\infty + \norm{ T q_{k-1} - T q^* }_\infty
\le  \norm{ q_k - T q_{k-1} }_\infty + \gamma \norm{ q_{k-1} - q^* }_\infty
\le  \norm{ q_k - T q_{k-1} }_\infty + \gamma \delta_{k-1}\,.
\end{align*}
Unfolding this and using $\delta_0 \le H_\gamma$,
\begin{align*}
\delta_K \le \gamma^K H_\gamma + H_\gamma \max_{1\le k \le K} \norm{ q_k - T q_{k-1} }_\infty \,.
\end{align*}
Taking a union bound over $k\in [K]$ and plugging in the bound from the previous item, we get
\begin{align*}
\delta_K 
\le 
H_\gamma \gamma^K + H_\gamma 
\left\{ (1+\sqrt{d}) \epx + \sqrt{d} H_\gamma \sqrt{\frac{\log\left(\frac{2|C|K}{\zeta}\right)}{2m}} \right\}\,.
\end{align*}
Finally, by our policy error bound,
\begin{align*}
\delta \le 2 H_\gamma^2
\left\{
(1+\sqrt{d}) \epx +
 \gamma^K +
 \sqrt{d} H_\gamma \sqrt{\frac{\log\left(\frac{2|C|K}{\zeta}\right)}{2m}} \right\}\,.
\end{align*}

\item 
Let $\hat \pi$ be the random policy computed by the algorithm.
Let $\mathcal{E}$ be the event of the previous part.
By the previous part, on $\mathcal{E}$,
\begin{align*}
v^* - v^{\hat \pi} \le \delta \boldsymbol{1}\,.
\end{align*}
Now, for any fixed $s\in \cS$, 
\begin{align*}
\EE{ v^*(s)-v^{\hat \pi}(s) } 
&= \EE{ (v^*(s)-v^{\hat \pi}(s))\oneb{\cE} } + \EE{ (v^*(s)-v^{\hat \pi}(s))\oneb{\cE^c} }  \\
&\le \EE{ \delta\oneb{\cE} } + \EE{H_\gamma \oneb{\cE^c} }  \\
&= \delta \Prob{\cE} + H_\gamma \Prob{\cE^c}   \\
&\le \delta + H_\gamma \zeta\,,
\end{align*}
where the last inequality used Q3.

Now, from the result of Q4,
  \begin{align*}
    \delta +
    H_\gamma\zeta
    &\le 2 H_\gamma^2 (1 + \sqrt{d}) \epx + 2 \underbrace{H_\gamma^2  \left[ \gamma^K + \sqrt{d} H_\gamma \sqrt{\frac{\log \left(\frac{2|C|K}{\zeta} \right)}{2m}} + \frac{\zeta}{2H_\gamma} \right]}_{\leq \epsilon} \leq 2 H_\gamma^2 (1 + \sqrt{d}) \epx + 2 \epsilon.
  \end{align*}

  Letting each of the last three terms above to be less than $\epsilon/3$, we get the following conditions:
  \begin{align*}
    K &\geq \frac{\log\left(3 H_\gamma^2/\epsilon \right)}{\log(1 / \gamma)}, \\
    \zeta &\leq 2\epsilon/(3H_\gamma), \quad \text{and} \\
    m &\geq \frac{9 H_\gamma^6 d}{2 \epsilon^2} \Bigg[\log(2|C|) + \log K + \log \left(3 H_\gamma / (2\epsilon) \right) \Bigg].
  \end{align*}

  Recalling that $|C| \leq d(d+1)/2$ gives us the desired result.
  
\item From Q1, we know that the query cost $O(Kd^2m)$, the runtime complexity $O(Kd^3mA)$, and the space complexity $O(d^2)$ are all polynomial in $A, d, K$, and $m$. Therefore, the result follows from Q5, which shoes that both $K$ and $m$ themselves have polynomial dependence on $H_\gamma, d$, and $1/\epsilon$, and that policy is $\delta$-suboptimal with $\delta = 2H_\gamma^2 (1 + \sqrt{d})_{\epx} + 2 \epsilon$.
  
\item 
It suffices to see that for any $q\in \R^{\cS \times \cA}$, $T q\in \cF_{\phi}$. Indeed, then for any $\theta$, $T\Pi f_\theta\in \cF_{\phi}$, which means that $\inf_{\theta'} \| f_{\theta'} - T \Pi f_{\theta} \|_\infty=0$.

Fix now $q\in \R^{\cS\times \cA}$. Let $v = Mq$.
Letting $Z\in \R^{d\times \nS}$ be defined using $Z(i,s') = \mu_i(s')$, notice that 
for $P\in \R^{\nS \nA \times \nS}$ it holds that 
$P =\Phi Z$ while $r = \Phi \theta_r$.
Hence,
\begin{align*}
T q = r + \gamma P v  =\Phi \theta_r + \gamma \Phi Z v = \Phi (\theta_r + \gamma Z v)\,,
\end{align*}
which shows that $Tq \in \cF_{\phi}$, finishing the proof.
\end{enumerate}
\end{solution*}


%\begin{question}
%\end{question}
%\begin{solution*}
%\qed\par\smallskip\hrule
%\end{solution*}


\bigskip
\bigskip

\noindent
\textbf{
Total for all questions: \arabic{DocPoints}}.
Of this, $30$ are bonus marks (i.e., $120$ marks worth $100\%$ on this problem set).

\end{document}
