<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <link rel="icon" href="/favicon.ico" type="image/x-icon"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>About | ML Theory</title> <meta name="generator" content="Jekyll v4.2.2" /> <meta property="og:title" content="About" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="CMPUT 654: Theoretical Foundations of Machine Learning F2023" /> <meta property="og:description" content="CMPUT 654: Theoretical Foundations of Machine Learning F2023" /> <link rel="canonical" href="http://localhost:4000/pages/about/" /> <meta property="og:url" content="http://localhost:4000/pages/about/" /> <meta property="og:site_name" content="ML Theory" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2023-09-25T08:54:31-06:00" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="About" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-09-25T08:54:31-06:00","datePublished":"2023-09-25T08:54:31-06:00","description":"CMPUT 654: Theoretical Foundations of Machine Learning F2023","headline":"About","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/pages/about/"},"url":"http://localhost:4000/pages/about/"}</script> <!-- End Jekyll SEO tag --> <!-- MathJax --> <!-- http://docs.mathjax.org/en/latest/web/start.html --> <!-- http://docs.mathjax.org/en/latest/web/configuration.html#web-configuration --> <!-- http://docs.mathjax.org/en/latest/options/input/tex.html --> <!-- http://docs.mathjax.org/en/latest/input/tex/eqnumbers.html --> <script> MathJax = { tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], processEscapes: true, tags: 'ams' } }; </script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <!-- Google fonts --> <!-- https://fonts.google.com/specimen/Merriweather?sidebar.open=true&selection.family=Merriweather:wght@400;900 --> <style> @import url('https://fonts.googleapis.com/css2?family=Merriweather:wght@400;900&display=swap'); </style> </head> <body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header"> <a href="http://localhost:4000/" class="site-title lh-tight"> ML Theory </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"> <div class="nav-category">Pages</div> <ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li><li class="nav-list-item"><a href="/pages/about/" class="nav-list-link active">About</a></li><li class="nav-list-item"><a href="/pages/lectures/" class="nav-list-link">Lectures</a></li><li class="nav-list-item"><a href="/pages/assignments/" class="nav-list-link">The work you do</a></li></ul> <div class="nav-category">Lecture Notes</div> <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Planning in MDPs category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/lecture-notes/planning-in-mdps" class="nav-list-link">Planning in MDPs</a><ul class="nav-list"><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec1/" class="nav-list-link">1. Introductions</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec2/" class="nav-list-link">2. The Fundamental Theorem</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec3/" class="nav-list-link">3. Value Iteration and Our First Lower Bound</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec4/" class="nav-list-link">4. Policy Iteration</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec5/" class="nav-list-link">5. Online Planning - Part I.</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec6/" class="nav-list-link">6. online planning - Part II.</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec7/" class="nav-list-link">7. Function Approximation</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec8/" class="nav-list-link">8. Approximate Policy Iteration</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec9/" class="nav-list-link">9. Limits of query-efficient planning</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec10/" class="nav-list-link">10. Planning under $q^*$ realizability</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec11/" class="nav-list-link">11. Planning under $v^*$ realizability (TensorPlan I.)</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec12/" class="nav-list-link">12. TensorPlan and eluder sequences</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec13/" class="nav-list-link">13. From API to Politex</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec14/" class="nav-list-link">14. Politex</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec15/" class="nav-list-link">15. From policy search to policy gradients</a></li><li class="nav-list-item "><a href="/lecture-notes/planning-in-mdps/lec16/" class="nav-list-link">16. Policy gradients</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Online RL category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/lecture-notes/online-rl" class="nav-list-link">Online RL</a><ul class="nav-list"><li class="nav-list-item "><a href="/lecture-notes/online-rl/lec23/" class="nav-list-link">23. Tabular MDPs</a></li><li class="nav-list-item "><a href="/lecture-notes/online-rl/lec24/" class="nav-list-link">24. Featurized MDPs</a></li><li class="nav-list-item "><a href="/lecture-notes/online-rl/lec22/" class="nav-list-link">22. Introduction</a></li></ul></li></ul> </nav> <footer class="site-footer"> Website of the course CMPUT 654: Theoretical Foundations of Machine Learning. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search ML Theory" aria-label="Search ML Theory" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content" role="main"> <h1 id="cmput-654-theoretical-foundations-of-machine-learning-f2023">CMPUT 654: Theoretical Foundations of Machine Learning F2023</h1> <p>Following Tong Zhang’s <a href="https://tongzhang-ml.org/lt-book/lt-book.pdf">book</a>, students will be introduced to the basic tools required to understand foundational results in learning theory and will get them prepared to read and understand a large portion of learning theory papers. The focus is on the the statistical approach to learning: The contents of the first 12 chapters from Tong Zhang’s book.</p> <h2 id="pre-requisites">Pre-requisites</h2> <p>Students are expected to follow (and even enjoy) mathematical proofs, deal with expressions involving probabilities and have a working knowledge of calculus and linear algebra.</p> <p>Basic probability, linear algebra and convex optimization is covered in Chapters 2, 3, 5, 7, 26, and 38 of the <a href="https://tor-lattimore.com/downloads/book/book.pdf">Bandit Algorithms book</a>. One very nice book that covers more, but is still highly recommended is <a href="http://people.bu.edu/pekoz/A_Second_Course_in_Probability-Ross-Pekoz.pdf">A Second Course in Probability Theory</a>. The book is available online and also in book format. Chapters 1, 3, 4, and 5 are most useful from here.</p> <h2 id="instructor">Instructor</h2> <ul> <li><a href="https://sites.ualberta.ca/~szepesva">Csaba Szepesvári</a></li> </ul> <h2 id="lecture-time">Lecture Time</h2> <p>Monday and Wednesdays from 3:30 PM - 4:50 PM (MST) in T 1-100.</p> <h3 id="office-hours">Office Hours</h3> <p>We use slack for discussion of short questions. If more time is needed, arrange it with the instructor using slack.</p> <!-- ## Grading The students will be graded on four problem sheets (with one warm-up sheet), worth 10% of the grade each, and a midterm worth 20%. The problem sheets and mid-term ought to take around 12 hours each to complete to a good standard. The remaining 40% of the grade will be awarded based on the quality of the final project. The students will likely need to spend at least 10 hours each week reading, thinking and writing in order to produce a good project. ## Weights and Deadlines | Component | Weight | Deadline | |:-------------| :--------| :-------------------------| | Assignment 1 | 10% | January 29, 2023 11:55pm | | Assignment 2 | 10% | February 12, 2023 11:55pm | | Midterm | 20% | February 26, 2023 11:55pm | | Project (Proposal) | 10% | March 5, 2023 11:55pm | | Assignment 3 | 10% | March 12, 2023 11:55pm | | Assignment 4 | 10% | March 26, 2023 11:55pm | | Project (Presentation) | 10% | April 11 and 12, 2023 (in class)| | Project (Report) | 20% | April 18, 2023 11:55pm | --> <!-- ## eClass We will use eclass for assignment submissions. The link to join eClass can be found [here](https://eclass.srv.ualberta.ca/course/view.php?id=76687). We will not use eClass for announcements and discussions. For these we will use Slack. --> <h2 id="slack-channel">Slack Channel</h2> <p>We will use Slack for everything. We have a separate workspace to discuss all topics related for this course. <!-- This channel is open to anyone who is on Amii slack. --> If you would like to join the channel please message the instructor. <!-- For discussions related to marking, assignment schedule, etc. we have a second channel `#cmput653-private-discussion-w2022`, which is by invitation only. --> <!-- The TAs will add anyone who is taking the course for credit to these slack channels. --> All announcements will be made on this channel. We strongly encourage all students to ask questions regarding course content on the Slack channel.</p> <!-- ## Google Meet Information The google meet information will be posted on the slack channel and on eClass. This is relevant up to the point when teaching becomes in-person. --> <!-- ## Grading Policies Can be found on [eClass](https://eclass.srv.ualberta.ca/course/view.php?id=76687). --> <h2 id="lectures-notes">Lectures Notes</h2> <p>The lecture notes for this year’s class are under the heading <strong>LECTURE NOTES</strong>.</p> <!-- ## Flipped Class For the first three weeks, as mentioned above, we will follow a flipped class format: Students coming to class are required to - read the associated lecture notes and/or watch the lecture recordings - prepare and vote on questions on the slack discussion channel In class time will be spent on a - quick review of the material - discussing the most voted questions - small group discussions of various topics --> <p><strong>Keywords:</strong> Theory, Machine learning, Statistical learning, Concentration inequalities, Uniform deviation bounds</p> <hr> <footer> <p><a href="#top" id="back-to-top">Back to top</a></p> <p class="text-small text-grey-dk-100 mb-0">Copyright &copy; 2023 ML Theory.</p> <div class="d-flex mt-2"> </div> </footer> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
